{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c762754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 14:27:20.644946: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-28 14:27:21.460754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bf7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkfilepath(filepath):\n",
    "    return os.path.exists(filepath)\n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    scan = nib.load(filepath)\n",
    "    data = scan.get_fdata()\n",
    "    return data\n",
    "\n",
    "def normalize(volume):\n",
    "    dmin = np.amin(volume)\n",
    "    dmax = np.amax(volume)\n",
    "    davg = np.average(volume)\n",
    "    volume = (volume-dmin)/davg\n",
    "    return volume\n",
    "\n",
    "def process_scan(path):\n",
    "    vol = read_nifti_file(path)\n",
    "    vol = normalize(vol)\n",
    "    return vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c96090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/lfs1/ashaji/Imputation_Problem/data/ADNI_final.xlsx', engine='openpyxl')\n",
    "df['SubjID'].replace('',np.nan,inplace=True)\n",
    "df['AGE_at_scan'].replace('',np.nan,inplace=True)\n",
    "df['DX'].replace('',np.nan,inplace=True)\n",
    "df.dropna(subset=['SubjID','AGE_at_scan','DX'], inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df.loc[df['SEX']=='M','SEX'] = 1\n",
    "df.loc[df['SEX']=='F','SEX'] = 0\n",
    "df.loc[df['DX']=='CN','DX'] = 0\n",
    "df.loc[df['DX']=='Dementia','DX'] = 2\n",
    "df.loc[df['DX']=='MCI','DX'] = 1\n",
    "df = df.sort_values(by = ['SubjID'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e285c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = [checkfilepath(str(x)) for x in df['ACCEL_DL_6DOF_2MM_T1']]\n",
    "cond0 = df['ACCEL_Preprocessed for DL?']=='yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b216b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conddwi = [checkfilepath(str(x)) for x in df['DWI_Matched_File_FA_Path_ENIGMATBSSspace_2MM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba2009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condt1 = [cond[i] & cond0[i]  for i in range(len(cond))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccff7cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjID</th>\n",
       "      <th>RID</th>\n",
       "      <th>NONACCEL_T1_SCAN_FILENAME</th>\n",
       "      <th>NONACCEL_T1_IMAGEID</th>\n",
       "      <th>NONACCEL_Path to RAW nifti</th>\n",
       "      <th>NONACCEL_Preprocessed for DL?</th>\n",
       "      <th>NONACCEL_DL_6DOF_2MM_T1</th>\n",
       "      <th>NONACCEL_DL_6DOF_2MM_MASK</th>\n",
       "      <th>NONACCEL_DL_6DOF_2MM_GM</th>\n",
       "      <th>NONACCEL_DL_6DOF_2MM_WM</th>\n",
       "      <th>...</th>\n",
       "      <th>DWI_Matched_File_L1_Path_ENIGMATBSSspace</th>\n",
       "      <th>DWI_Matched_File_MD_Path_ENIGMATBSSspace</th>\n",
       "      <th>DWI_Matched_File_RD_Path_ENIGMATBSSspace</th>\n",
       "      <th>T1_Path_ENIGMATBSSspace</th>\n",
       "      <th>DWI_Matched_File_FA_Path_ENIGMATBSSspace_2MM</th>\n",
       "      <th>DWI_Matched_File_L1_Path_ENIGMATBSSspace_2MM</th>\n",
       "      <th>DWI_Matched_File_MD_Path_ENIGMATBSSspace_2MM</th>\n",
       "      <th>DWI_Matched_File_RD_Path_ENIGMATBSSspace_2MM</th>\n",
       "      <th>T1_Path_ENIGMATBSSspace_2MM</th>\n",
       "      <th>DWI Preprocessing Pipeline (old=ADNI2 - new=ADNI3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>295</td>\n",
       "      <td>002_S_0295_20060418_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>45108.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>295</td>\n",
       "      <td>002_S_0295_20061102_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>40966.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>295</td>\n",
       "      <td>002_S_0295_20070525_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>64025.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>295</td>\n",
       "      <td>002_S_0295_20080723_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>123685.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>295</td>\n",
       "      <td>002_S_0295_20090522_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>150177.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>295</td>\n",
       "      <td>002_S_0295_20100513_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>291869.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>295</td>\n",
       "      <td>002_S_0295_20110602_A2_T1_3T_nonaccel_Preproc</td>\n",
       "      <td>241350.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>295</td>\n",
       "      <td>002_S_0295_20120510_A2_T1_3T_nonaccel_Preproc</td>\n",
       "      <td>308078.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>ADNI3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20150609_A2_T1_3T_nonaccel_Preproc</td>\n",
       "      <td>649030.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20140501_A2_T1_3T_nonaccel_Preproc</td>\n",
       "      <td>424741.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20130510_A2_T1_3T_nonaccel_Preproc</td>\n",
       "      <td>373133.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20120515_A2_T1_3T_nonaccel_Preproc</td>\n",
       "      <td>312701.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20110616_A2_T1_3T_nonaccel_Preproc</td>\n",
       "      <td>242895.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>ADNI3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20090504_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>149740.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20080731_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>120917.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20070601_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>60008.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20061115_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>79122.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>413</td>\n",
       "      <td>002_S_0413_20100506_A1_T1_1.5T_nonaccel_Preproc</td>\n",
       "      <td>291873.0</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/Organi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>/nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubjID  RID                        NONACCEL_T1_SCAN_FILENAME  \\\n",
       "0   002_S_0295  295  002_S_0295_20060418_A1_T1_1.5T_nonaccel_Preproc   \n",
       "1   002_S_0295  295  002_S_0295_20061102_A1_T1_1.5T_nonaccel_Preproc   \n",
       "2   002_S_0295  295  002_S_0295_20070525_A1_T1_1.5T_nonaccel_Preproc   \n",
       "3   002_S_0295  295  002_S_0295_20080723_A1_T1_1.5T_nonaccel_Preproc   \n",
       "4   002_S_0295  295  002_S_0295_20090522_A1_T1_1.5T_nonaccel_Preproc   \n",
       "5   002_S_0295  295  002_S_0295_20100513_A1_T1_1.5T_nonaccel_Preproc   \n",
       "6   002_S_0295  295    002_S_0295_20110602_A2_T1_3T_nonaccel_Preproc   \n",
       "7   002_S_0295  295    002_S_0295_20120510_A2_T1_3T_nonaccel_Preproc   \n",
       "8   002_S_0413  413                                              NaN   \n",
       "9   002_S_0413  413    002_S_0413_20150609_A2_T1_3T_nonaccel_Preproc   \n",
       "10  002_S_0413  413    002_S_0413_20140501_A2_T1_3T_nonaccel_Preproc   \n",
       "11  002_S_0413  413    002_S_0413_20130510_A2_T1_3T_nonaccel_Preproc   \n",
       "12  002_S_0413  413    002_S_0413_20120515_A2_T1_3T_nonaccel_Preproc   \n",
       "13  002_S_0413  413    002_S_0413_20110616_A2_T1_3T_nonaccel_Preproc   \n",
       "14  002_S_0413  413                                              NaN   \n",
       "15  002_S_0413  413  002_S_0413_20090504_A1_T1_1.5T_nonaccel_Preproc   \n",
       "16  002_S_0413  413  002_S_0413_20080731_A1_T1_1.5T_nonaccel_Preproc   \n",
       "17  002_S_0413  413  002_S_0413_20070601_A1_T1_1.5T_nonaccel_Preproc   \n",
       "18  002_S_0413  413  002_S_0413_20061115_A1_T1_1.5T_nonaccel_Preproc   \n",
       "19  002_S_0413  413  002_S_0413_20100506_A1_T1_1.5T_nonaccel_Preproc   \n",
       "\n",
       "    NONACCEL_T1_IMAGEID                         NONACCEL_Path to RAW nifti  \\\n",
       "0               45108.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "1               40966.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "2               64025.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "3              123685.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "4              150177.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "5              291869.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "6              241350.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "7              308078.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "8                   NaN                                                NaN   \n",
       "9              649030.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "10             424741.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "11             373133.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "12             312701.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "13             242895.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "14                  NaN                                                NaN   \n",
       "15             149740.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "16             120917.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "17              60008.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "18              79122.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "19             291873.0  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "\n",
       "   NONACCEL_Preprocessed for DL?  \\\n",
       "0                            yes   \n",
       "1                            yes   \n",
       "2                            yes   \n",
       "3                            yes   \n",
       "4                            yes   \n",
       "5                            yes   \n",
       "6                            yes   \n",
       "7                            yes   \n",
       "8                            NaN   \n",
       "9                            yes   \n",
       "10                           yes   \n",
       "11                           yes   \n",
       "12                           yes   \n",
       "13                           yes   \n",
       "14                           NaN   \n",
       "15                           yes   \n",
       "16                           yes   \n",
       "17                           yes   \n",
       "18                           yes   \n",
       "19                           yes   \n",
       "\n",
       "                              NONACCEL_DL_6DOF_2MM_T1  \\\n",
       "0   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "1   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "2   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "3   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "4   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "5   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "6   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "7   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "8                                                 NaN   \n",
       "9   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "10  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "11  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "12  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "13  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "14                                                NaN   \n",
       "15  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "16  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "17  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "18  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "19  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "\n",
       "                            NONACCEL_DL_6DOF_2MM_MASK  \\\n",
       "0   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "1   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "2   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "3   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "4   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "5   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "6   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "7   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "8                                                 NaN   \n",
       "9   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "10  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "11  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "12  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "13  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "14                                                NaN   \n",
       "15  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "16  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "17  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "18  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "19  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "\n",
       "                              NONACCEL_DL_6DOF_2MM_GM  \\\n",
       "0   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "1   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "2   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "3   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "4   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "5   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "6   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "7   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "8                                                 NaN   \n",
       "9   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "10  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "11  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "12  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "13  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "14                                                NaN   \n",
       "15  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "16  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "17  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "18  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "19  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...   \n",
       "\n",
       "                              NONACCEL_DL_6DOF_2MM_WM  ...  \\\n",
       "0   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "1   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "2   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "3   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "4   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "5   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "6   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "7   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "8                                                 NaN  ...   \n",
       "9   /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "10  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "11  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "12  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "13  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "14                                                NaN  ...   \n",
       "15  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "16  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "17  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "18  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "19  /nas/bioint-data/neuroimaging-data/ADNI/6DOF/0...  ...   \n",
       "\n",
       "             DWI_Matched_File_L1_Path_ENIGMATBSSspace  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "             DWI_Matched_File_MD_Path_ENIGMATBSSspace  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "             DWI_Matched_File_RD_Path_ENIGMATBSSspace  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "                              T1_Path_ENIGMATBSSspace  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "         DWI_Matched_File_FA_Path_ENIGMATBSSspace_2MM  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "         DWI_Matched_File_L1_Path_ENIGMATBSSspace_2MM  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "         DWI_Matched_File_MD_Path_ENIGMATBSSspace_2MM  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "         DWI_Matched_File_RD_Path_ENIGMATBSSspace_2MM  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "                          T1_Path_ENIGMATBSSspace_2MM  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  /nas/bioint-data/neuroimaging-data/ADNI/Organi...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "   DWI Preprocessing Pipeline (old=ADNI2 - new=ADNI3)  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                               ADNI3  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                              ADNI3  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "\n",
       "[20 rows x 121 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b84b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs1/ashaji/condawork/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random as pyrandom\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, accuracy_score, f1_score, precision_score, recall_score, auc, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"5\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01443f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter config\n",
    "\n",
    "init_lr = 1e-4\n",
    "epochs = 50\n",
    "early_stop = 100\n",
    "seed = 53\n",
    "drop_out = 0.5\n",
    "weight_decay = 1e-4\n",
    "\n",
    "batch_size=4\n",
    "test_batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0706a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5570"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "125eb63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 14:28:47.421901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10534 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0d:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3DCNN_Metis_T1andDWI\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inp0 (InputLayer)              [(None, 91, 109, 91  0           []                               \n",
      "                                , 1)]                                                             \n",
      "                                                                                                  \n",
      " inp1 (InputLayer)              [(None, 91, 109, 91  0           []                               \n",
      "                                , 1)]                                                             \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 91, 109, 91,  896         ['inp0[0][0]']                   \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 91, 109, 91,  896         ['inp1[0][0]']                   \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " instance_normalization (Instan  (None, 91, 109, 91,  0          ['conv3d[0][0]']                 \n",
      " ceNormalization)                32)                                                              \n",
      "                                                                                                  \n",
      " instance_normalization_6 (Inst  (None, 91, 109, 91,  0          ['conv3d_6[0][0]']               \n",
      " anceNormalization)              32)                                                              \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 45, 54, 45,   0           ['instance_normalization[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_5 (MaxPooling3D)  (None, 45, 54, 45,   0          ['instance_normalization_6[0][0]'\n",
      "                                32)                              ]                                \n",
      "                                                                                                  \n",
      " tf.nn.relu (TFOpLambda)        (None, 45, 54, 45,   0           ['max_pooling3d[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_6 (TFOpLambda)      (None, 45, 54, 45,   0           ['max_pooling3d_5[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 45, 54, 45,   55360       ['tf.nn.relu[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 45, 54, 45,   55360       ['tf.nn.relu_6[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " instance_normalization_1 (Inst  (None, 45, 54, 45,   0          ['conv3d_1[0][0]']               \n",
      " anceNormalization)             64)                                                               \n",
      "                                                                                                  \n",
      " instance_normalization_7 (Inst  (None, 45, 54, 45,   0          ['conv3d_7[0][0]']               \n",
      " anceNormalization)             64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 22, 27, 22,   0          ['instance_normalization_1[0][0]'\n",
      "                                64)                              ]                                \n",
      "                                                                                                  \n",
      " max_pooling3d_6 (MaxPooling3D)  (None, 22, 27, 22,   0          ['instance_normalization_7[0][0]'\n",
      "                                64)                              ]                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_1 (TFOpLambda)      (None, 22, 27, 22,   0           ['max_pooling3d_1[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_7 (TFOpLambda)      (None, 22, 27, 22,   0           ['max_pooling3d_6[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 22, 27, 22,   221312      ['tf.nn.relu_1[0][0]']           \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 22, 27, 22,   221312      ['tf.nn.relu_7[0][0]']           \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " instance_normalization_2 (Inst  (None, 22, 27, 22,   0          ['conv3d_2[0][0]']               \n",
      " anceNormalization)             128)                                                              \n",
      "                                                                                                  \n",
      " instance_normalization_8 (Inst  (None, 22, 27, 22,   0          ['conv3d_8[0][0]']               \n",
      " anceNormalization)             128)                                                              \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPooling3D)  (None, 11, 13, 11,   0          ['instance_normalization_2[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " max_pooling3d_7 (MaxPooling3D)  (None, 11, 13, 11,   0          ['instance_normalization_8[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_2 (TFOpLambda)      (None, 11, 13, 11,   0           ['max_pooling3d_2[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " tf.nn.relu_8 (TFOpLambda)      (None, 11, 13, 11,   0           ['max_pooling3d_7[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 11, 13, 11,   884992      ['tf.nn.relu_2[0][0]']           \n",
      "                                256)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 11, 13, 11,   884992      ['tf.nn.relu_8[0][0]']           \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " instance_normalization_3 (Inst  (None, 11, 13, 11,   0          ['conv3d_3[0][0]']               \n",
      " anceNormalization)             256)                                                              \n",
      "                                                                                                  \n",
      " instance_normalization_9 (Inst  (None, 11, 13, 11,   0          ['conv3d_9[0][0]']               \n",
      " anceNormalization)             256)                                                              \n",
      "                                                                                                  \n",
      " max_pooling3d_3 (MaxPooling3D)  (None, 5, 6, 5, 256  0          ['instance_normalization_3[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " max_pooling3d_8 (MaxPooling3D)  (None, 5, 6, 5, 256  0          ['instance_normalization_9[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_3 (TFOpLambda)      (None, 5, 6, 5, 256  0           ['max_pooling3d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.relu_9 (TFOpLambda)      (None, 5, 6, 5, 256  0           ['max_pooling3d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 5, 6, 5, 256  1769728     ['tf.nn.relu_3[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 5, 6, 5, 256  1769728     ['tf.nn.relu_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " instance_normalization_4 (Inst  (None, 5, 6, 5, 256  0          ['conv3d_4[0][0]']               \n",
      " anceNormalization)             )                                                                 \n",
      "                                                                                                  \n",
      " instance_normalization_10 (Ins  (None, 5, 6, 5, 256  0          ['conv3d_10[0][0]']              \n",
      " tanceNormalization)            )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling3d_4 (MaxPooling3D)  (None, 2, 3, 2, 256  0          ['instance_normalization_4[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " max_pooling3d_9 (MaxPooling3D)  (None, 2, 3, 2, 256  0          ['instance_normalization_10[0][0]\n",
      "                                )                                ']                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_4 (TFOpLambda)      (None, 2, 3, 2, 256  0           ['max_pooling3d_4[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.relu_10 (TFOpLambda)     (None, 2, 3, 2, 256  0           ['max_pooling3d_9[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 2, 3, 2, 64)  16448       ['tf.nn.relu_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 2, 3, 2, 64)  16448       ['tf.nn.relu_10[0][0]']          \n",
      "                                                                                                  \n",
      " instance_normalization_5 (Inst  (None, 2, 3, 2, 64)  0          ['conv3d_5[0][0]']               \n",
      " anceNormalization)                                                                               \n",
      "                                                                                                  \n",
      " instance_normalization_11 (Ins  (None, 2, 3, 2, 64)  0          ['conv3d_11[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " tf.nn.relu_5 (TFOpLambda)      (None, 2, 3, 2, 64)  0           ['instance_normalization_5[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_11 (TFOpLambda)     (None, 2, 3, 2, 64)  0           ['instance_normalization_11[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " average_pooling3d (AveragePool  (None, 1, 1, 1, 64)  0          ['tf.nn.relu_5[0][0]']           \n",
      " ing3D)                                                                                           \n",
      "                                                                                                  \n",
      " average_pooling3d_1 (AveragePo  (None, 1, 1, 1, 64)  0          ['tf.nn.relu_11[0][0]']          \n",
      " oling3D)                                                                                         \n",
      "                                                                                                  \n",
      " drop0 (Dropout)                (None, 1, 1, 1, 64)  0           ['average_pooling3d[0][0]']      \n",
      "                                                                                                  \n",
      " drop2 (Dropout)                (None, 1, 1, 1, 64)  0           ['average_pooling3d_1[0][0]']    \n",
      "                                                                                                  \n",
      " flatten1 (Flatten)             (None, 64)           0           ['drop0[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten2 (Flatten)             (None, 64)           0           ['drop2[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128)          0           ['flatten1[0][0]',               \n",
      "                                                                  'flatten2[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           2080        ['dense[0][0]']                  \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_2 (Dense)                (None, 16)           528         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " DX (Dense)                     (None, 3)            51          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,908,387\n",
      "Trainable params: 5,908,387\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def getCNN(width = 91,height = 109, depth = 91):\n",
    "    \n",
    "    def conv_block(inp,filt,name):\n",
    "        inp = tf.keras.layers.Conv3D(filt,3,strides=1,padding='same')(inp)\n",
    "        inp = tfa.layers.InstanceNormalization(center=False,scale=False)(inp)\n",
    "        inp = tf.keras.layers.MaxPooling3D(2,strides=2,padding = 'valid')(inp)\n",
    "        inp = tf.nn.relu(inp)\n",
    "        return inp\n",
    "    \n",
    "    img0 = tf.keras.Input((91,109,91,1),name='inp0')\n",
    "    inp0 = conv_block(img0,32,'conv_block1')\n",
    "    inp0 = conv_block(inp0,64,'conv_block2')\n",
    "    inp0 = conv_block(inp0,128,'conv_block3')\n",
    "    inp0 = conv_block(inp0,256,'conv_block4')\n",
    "    inp0 = conv_block(inp0,256,'conv_block5')\n",
    "    \n",
    "    ##LAST LAYER\n",
    "    \n",
    "    inp0 = tf.keras.layers.Conv3D(64,1,strides=1,padding='same')(inp0)\n",
    "    inp0 = tfa.layers.InstanceNormalization(center=False,scale=False)(inp0)\n",
    "    inp0 = tf.nn.relu(inp0)\n",
    "    inp0 = tf.keras.layers.AveragePooling3D(2,2,'valid')(inp0)\n",
    "    \n",
    "    inp0 = tf.keras.layers.Dropout(rate=0.2,name='drop0')(inp0)\n",
    "    \n",
    "#     out0 = tf.keras.layers.Conv3D(1,1,strides=1,name='regconv1')(inp0)\n",
    "    out0 = tf.keras.layers.Flatten(name='flatten1')(inp0)\n",
    "    \n",
    "    ######################\n",
    "    \n",
    "    img1 = tf.keras.Input((91,109,91,1),name='inp1')\n",
    "    inp1 = conv_block(img1,32,'conv_block11')\n",
    "    inp1 = conv_block(inp1,64,'conv_block12')\n",
    "    inp1 = conv_block(inp1,128,'conv_block13')\n",
    "    inp1 = conv_block(inp1,256,'conv_block14')\n",
    "    inp1 = conv_block(inp1,256,'conv_block15')\n",
    "    \n",
    "    ##LAST LAYER\n",
    "    \n",
    "    inp1 = tf.keras.layers.Conv3D(64,1,strides=1,padding='same')(inp1)\n",
    "    inp1 = tfa.layers.InstanceNormalization(center=False,scale=False)(inp1)\n",
    "    inp1 = tf.nn.relu(inp1)\n",
    "    inp1 = tf.keras.layers.AveragePooling3D(2,2,'valid')(inp1)\n",
    "    \n",
    "    inp1 = tf.keras.layers.Dropout(rate=0.2,name='drop2')(inp1)\n",
    "    \n",
    "#     out1 = tf.keras.layers.Conv3D(1,1,strides=1,name='regconv2')(inp1)\n",
    "    out1 = tf.keras.layers.Flatten(name='flatten2')(inp1)\n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate()([out0,out1])\n",
    "    outx = tf.keras.layers.Dense(64,activation='relu')(concat) \n",
    "    outx = tf.keras.layers.Dense(32,activation='relu')(outx) \n",
    "    outx = tf.keras.layers.Dense(16,activation='relu')(outx) \n",
    "    out2 = tf.keras.layers.Dense(units=3,activation ='softmax', name='DX')(outx)\n",
    "    \n",
    "    model = keras.Model([img0,img1],out2,name='3DCNN_Metis_T1andDWI')\n",
    "    return model\n",
    "\n",
    "model = getCNN()\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ba70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1dwi = df.loc[[(condt1[i] and conddwi[i]) for i in range(len(condt1))]  , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd18fc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1dwi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e0e36038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543, 155, 79)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (np.ceil(0.7*len(t1dwistr))-1).astype(int)\n",
    "q = (np.ceil(0.9*len(t1dwistr))-2).astype(int)\n",
    "r = len(t1dwistr)\n",
    "trainn = p\n",
    "valn  = r - q\n",
    "testn   = q - p\n",
    "trainn, testn, valn\n",
    "trainall = t1dwistr[:p]\n",
    "testall  = t1dwistr[p:q]\n",
    "valall   = t1dwistr[q:]\n",
    "len(trainall), len(testall), len(valall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f87eca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamix = [train,trainall,valall]\n",
    "alltrain = pd.concat(datamix)\n",
    "alltrain = alltrain.sort_values(by = ['SubjID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "20dbffdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "563500b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608, 153, 761)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (np.ceil(0.8*len(alltrain))-1).astype(int)\n",
    "q = len(alltrain)\n",
    "trainn = p\n",
    "# valn  = r - q\n",
    "valn   = q - p\n",
    "trainn, valn, trainn + valn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3b6634f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 152)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p += 1\n",
    "trainds = alltrain[:p]\n",
    "valds   = alltrain[p:]\n",
    "len(trainds),len(valds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7661c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.71518987341773"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testall[testall.DX == 0].loc[:,'AGE_at_scan'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "80367e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trainds['SubjID']:\n",
    "    for j in testall['SubjID']:\n",
    "        if i==j:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fe461480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='DX', ylabel='Count'>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(data=trainds.DX)\n",
    "sns.histplot(data=testall.DX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ad6e328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def rotate(self,vol):\n",
    "        def scipy_rotate(vol):\n",
    "            angles = [-20,-10,-5,0,5,10,20]\n",
    "            angle = pyrandom.choice(angles)\n",
    "            vol = ndimage.rotate(vol,angle,reshape=False)\n",
    "            vol[vol<0] = 0\n",
    "            vol[vol>1] = 1\n",
    "            return vol\n",
    "        aug_vol = tf.numpy_function(scipy_rotate,[vol],tf.float32)\n",
    "        return aug_vol\n",
    "\n",
    "    def preprocessing(self,vol):\n",
    "        if(self.isTrain):\n",
    "            vol1 = self.rotate(vol)\n",
    "            vol1 = tf.expand_dims(vol1,axis=3)\n",
    "        else:\n",
    "            vol1 = tf.expand_dims(vol,axis=3)\n",
    "        return vol1\n",
    "    \n",
    "    def read_scan(self,path):\n",
    "        scan = nib.load(path)\n",
    "        volume = scan.get_fdata()\n",
    "        min = np.amax(volume)\n",
    "        max = np.amin(volume)\n",
    "        volume = (volume - min) / (max - min)\n",
    "        volume = volume.astype(\"float32\")\n",
    "        return volume\n",
    "\n",
    "    def __init__(self,data, batch_size, sample_weights=None,isTrain=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_weights = sample_weights\n",
    "        self.isTrain = isTrain\n",
    "\n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ####\n",
    "        t1  = self.data['ACCEL_DL_6DOF_2MM_T1'].tolist()\n",
    "        dwi = self.data['DWI_Matched_File_FA_Path_ENIGMATBSSspace_2MM'].tolist()\n",
    "        labels = self.data['DX']\n",
    "        labels = keras.utils.to_categorical(labels)\n",
    "        \n",
    "        batch_t1 = t1[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_dwi = dwi[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_y = labels[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        \n",
    "        t1_imgs = np.asarray([self.preprocessing(self.read_scan(path)) for path in batch_t1])\n",
    "        dwi_imgs = np.asarray([self.preprocessing(self.read_scan(path)) for path in batch_dwi])\n",
    "        ####\n",
    "        return ([t1_imgs,dwi_imgs], np.array(batch_y))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if(self.isTrain):\n",
    "            self.data = self.data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "93ecc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_train = DataGenerator(trainds,batch_size,isTrain=True)\n",
    "dg_val = DataGenerator(valds,batch_size,isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f3349b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_testall = DataGenerator(testall,4,isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7205267f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 91, 109, 91, 1)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfda98eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5c044676d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dg_train[0][0][0][1][90],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6e49391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14207/2532890018.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 07:19:09.357986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - ETA: 0s - loss: 0.9409 - auc: 0.7347 - Precision: 0.5840 - Recall: 0.5140 - categorical_accuracy: 0.5928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 07:23:21.770477: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 269s 2s/step - loss: 0.9409 - auc: 0.7347 - Precision: 0.5840 - Recall: 0.5140 - categorical_accuracy: 0.5928 - val_loss: 0.8971 - val_auc: 0.7575 - val_Precision: 0.6053 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 2/200\n",
      "153/153 [==============================] - 251s 2s/step - loss: 0.9178 - auc: 0.7474 - Precision: 0.5904 - Recall: 0.5681 - categorical_accuracy: 0.5928 - val_loss: 0.8905 - val_auc: 0.7793 - val_Precision: 0.6053 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 3/200\n",
      "153/153 [==============================] - 241s 2s/step - loss: 0.9062 - auc: 0.7594 - Precision: 0.5896 - Recall: 0.5189 - categorical_accuracy: 0.5928 - val_loss: 0.8781 - val_auc: 0.7875 - val_Precision: 0.6053 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 4/200\n",
      "153/153 [==============================] - 243s 2s/step - loss: 0.9036 - auc: 0.7539 - Precision: 0.5963 - Recall: 0.5747 - categorical_accuracy: 0.5928 - val_loss: 0.8755 - val_auc: 0.7815 - val_Precision: 0.6053 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 5/200\n",
      "153/153 [==============================] - 242s 2s/step - loss: 0.9021 - auc: 0.7531 - Precision: 0.6014 - Recall: 0.5747 - categorical_accuracy: 0.5928 - val_loss: 0.8693 - val_auc: 0.7881 - val_Precision: 0.6053 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 6/200\n",
      "153/153 [==============================] - 244s 2s/step - loss: 0.8934 - auc: 0.7620 - Precision: 0.5993 - Recall: 0.5747 - categorical_accuracy: 0.5928 - val_loss: 0.8707 - val_auc: 0.7975 - val_Precision: 0.6053 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 7/200\n",
      "153/153 [==============================] - 249s 2s/step - loss: 0.8972 - auc: 0.7552 - Precision: 0.5959 - Recall: 0.5714 - categorical_accuracy: 0.5928 - val_loss: 0.8847 - val_auc: 0.7889 - val_Precision: 0.6667 - val_Recall: 0.5132 - val_categorical_accuracy: 0.6053\n",
      "Epoch 8/200\n",
      "153/153 [==============================] - 251s 2s/step - loss: 0.8902 - auc: 0.7627 - Precision: 0.6000 - Recall: 0.5567 - categorical_accuracy: 0.5928 - val_loss: 0.8600 - val_auc: 0.8032 - val_Precision: 0.6053 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 9/200\n",
      "153/153 [==============================] - 243s 2s/step - loss: 0.8770 - auc: 0.7731 - Precision: 0.6174 - Recall: 0.5484 - categorical_accuracy: 0.5961 - val_loss: 0.9100 - val_auc: 0.8047 - val_Precision: 0.8571 - val_Recall: 0.0395 - val_categorical_accuracy: 0.6053\n",
      "Epoch 10/200\n",
      "153/153 [==============================] - 248s 2s/step - loss: 0.8805 - auc: 0.7703 - Precision: 0.6059 - Recall: 0.5074 - categorical_accuracy: 0.5895 - val_loss: 0.8519 - val_auc: 0.8034 - val_Precision: 0.6357 - val_Recall: 0.5395 - val_categorical_accuracy: 0.6053\n",
      "Epoch 11/200\n",
      "153/153 [==============================] - 248s 2s/step - loss: 0.8565 - auc: 0.7890 - Precision: 0.6389 - Recall: 0.5172 - categorical_accuracy: 0.6059 - val_loss: 0.8499 - val_auc: 0.8092 - val_Precision: 0.7143 - val_Recall: 0.4276 - val_categorical_accuracy: 0.6118\n",
      "Epoch 12/200\n",
      "153/153 [==============================] - 242s 2s/step - loss: 0.8515 - auc: 0.7903 - Precision: 0.6582 - Recall: 0.5090 - categorical_accuracy: 0.5846 - val_loss: 0.8346 - val_auc: 0.8102 - val_Precision: 0.6250 - val_Recall: 0.5921 - val_categorical_accuracy: 0.6053\n",
      "Epoch 13/200\n",
      "153/153 [==============================] - 240s 2s/step - loss: 0.8456 - auc: 0.7931 - Precision: 0.6652 - Recall: 0.4959 - categorical_accuracy: 0.5813 - val_loss: 0.8288 - val_auc: 0.8142 - val_Precision: 0.6207 - val_Recall: 0.5921 - val_categorical_accuracy: 0.6053\n",
      "Epoch 14/200\n",
      "153/153 [==============================] - 242s 2s/step - loss: 0.8249 - auc: 0.8039 - Precision: 0.6796 - Recall: 0.5189 - categorical_accuracy: 0.6141 - val_loss: 0.8083 - val_auc: 0.8195 - val_Precision: 0.7300 - val_Recall: 0.4803 - val_categorical_accuracy: 0.6053\n",
      "Epoch 15/200\n",
      "153/153 [==============================] - 243s 2s/step - loss: 0.8028 - auc: 0.8170 - Precision: 0.7182 - Recall: 0.5107 - categorical_accuracy: 0.6486 - val_loss: 0.7862 - val_auc: 0.8242 - val_Precision: 0.6972 - val_Recall: 0.5000 - val_categorical_accuracy: 0.6118\n",
      "Epoch 16/200\n",
      "153/153 [==============================] - 246s 2s/step - loss: 0.7859 - auc: 0.8242 - Precision: 0.7271 - Recall: 0.5205 - categorical_accuracy: 0.6502 - val_loss: 0.8096 - val_auc: 0.8292 - val_Precision: 0.8356 - val_Recall: 0.4013 - val_categorical_accuracy: 0.6711\n",
      "Epoch 17/200\n",
      "153/153 [==============================] - 241s 2s/step - loss: 0.7671 - auc: 0.8329 - Precision: 0.7327 - Recall: 0.5222 - categorical_accuracy: 0.6634 - val_loss: 0.8422 - val_auc: 0.8122 - val_Precision: 0.8667 - val_Recall: 0.3421 - val_categorical_accuracy: 0.6579\n",
      "Epoch 18/200\n",
      "153/153 [==============================] - 247s 2s/step - loss: 0.7521 - auc: 0.8447 - Precision: 0.7454 - Recall: 0.5287 - categorical_accuracy: 0.6732 - val_loss: 0.7613 - val_auc: 0.8369 - val_Precision: 0.6587 - val_Recall: 0.5461 - val_categorical_accuracy: 0.6053\n",
      "Epoch 19/200\n",
      "153/153 [==============================] - 246s 2s/step - loss: 0.7187 - auc: 0.8551 - Precision: 0.7554 - Recall: 0.5780 - categorical_accuracy: 0.7044 - val_loss: 0.7785 - val_auc: 0.8383 - val_Precision: 0.6449 - val_Recall: 0.5855 - val_categorical_accuracy: 0.6316\n",
      "Epoch 20/200\n",
      "153/153 [==============================] - 244s 2s/step - loss: 0.6760 - auc: 0.8784 - Precision: 0.7608 - Recall: 0.6371 - categorical_accuracy: 0.7258 - val_loss: 0.7339 - val_auc: 0.8490 - val_Precision: 0.6906 - val_Recall: 0.6316 - val_categorical_accuracy: 0.6776\n",
      "Epoch 21/200\n",
      "153/153 [==============================] - 244s 2s/step - loss: 0.6459 - auc: 0.8892 - Precision: 0.7619 - Recall: 0.6831 - categorical_accuracy: 0.7422 - val_loss: 0.7595 - val_auc: 0.8386 - val_Precision: 0.6643 - val_Recall: 0.6118 - val_categorical_accuracy: 0.6579\n",
      "Epoch 22/200\n",
      "153/153 [==============================] - 252s 2s/step - loss: 0.5968 - auc: 0.9100 - Precision: 0.7887 - Recall: 0.7110 - categorical_accuracy: 0.7635 - val_loss: 0.7861 - val_auc: 0.8313 - val_Precision: 0.6438 - val_Recall: 0.6184 - val_categorical_accuracy: 0.6382\n",
      "Epoch 23/200\n",
      "153/153 [==============================] - 244s 2s/step - loss: 0.5547 - auc: 0.9255 - Precision: 0.8050 - Recall: 0.7455 - categorical_accuracy: 0.7833 - val_loss: 0.7900 - val_auc: 0.8238 - val_Precision: 0.6573 - val_Recall: 0.6184 - val_categorical_accuracy: 0.6447\n",
      "Epoch 24/200\n",
      "153/153 [==============================] - 246s 2s/step - loss: 0.4961 - auc: 0.9391 - Precision: 0.8213 - Recall: 0.7849 - categorical_accuracy: 0.8062 - val_loss: 0.8078 - val_auc: 0.8356 - val_Precision: 0.6667 - val_Recall: 0.5921 - val_categorical_accuracy: 0.6513\n",
      "Epoch 25/200\n",
      "153/153 [==============================] - 246s 2s/step - loss: 0.4703 - auc: 0.9434 - Precision: 0.8308 - Recall: 0.7980 - categorical_accuracy: 0.8144 - val_loss: 0.8920 - val_auc: 0.8403 - val_Precision: 0.6510 - val_Recall: 0.6382 - val_categorical_accuracy: 0.6447\n",
      "Epoch 26/200\n",
      "153/153 [==============================] - 240s 2s/step - loss: 0.4765 - auc: 0.9396 - Precision: 0.8190 - Recall: 0.7947 - categorical_accuracy: 0.8095 - val_loss: 0.7826 - val_auc: 0.8353 - val_Precision: 0.6803 - val_Recall: 0.6579 - val_categorical_accuracy: 0.6711\n",
      "Epoch 27/200\n",
      "153/153 [==============================] - 240s 2s/step - loss: 0.4050 - auc: 0.9585 - Precision: 0.8487 - Recall: 0.8292 - categorical_accuracy: 0.8424 - val_loss: 0.8366 - val_auc: 0.8246 - val_Precision: 0.6690 - val_Recall: 0.6382 - val_categorical_accuracy: 0.6513\n",
      "Epoch 28/200\n",
      "153/153 [==============================] - 250s 2s/step - loss: 0.3758 - auc: 0.9661 - Precision: 0.8555 - Recall: 0.8358 - categorical_accuracy: 0.8506 - val_loss: 1.0586 - val_auc: 0.8313 - val_Precision: 0.6133 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 29/200\n",
      "153/153 [==============================] - 246s 2s/step - loss: 0.3938 - auc: 0.9600 - Precision: 0.8536 - Recall: 0.8424 - categorical_accuracy: 0.8522 - val_loss: 0.9531 - val_auc: 0.8224 - val_Precision: 0.6467 - val_Recall: 0.6382 - val_categorical_accuracy: 0.6513\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 248s 2s/step - loss: 0.3533 - auc: 0.9681 - Precision: 0.8645 - Recall: 0.8588 - categorical_accuracy: 0.8604 - val_loss: 0.8910 - val_auc: 0.8117 - val_Precision: 0.6291 - val_Recall: 0.6250 - val_categorical_accuracy: 0.6250\n",
      "Epoch 31/200\n",
      "153/153 [==============================] - 247s 2s/step - loss: 0.3332 - auc: 0.9725 - Precision: 0.8673 - Recall: 0.8588 - categorical_accuracy: 0.8621 - val_loss: 1.1731 - val_auc: 0.8317 - val_Precision: 0.6556 - val_Recall: 0.6513 - val_categorical_accuracy: 0.6513\n",
      "Epoch 32/200\n",
      "153/153 [==============================] - 243s 2s/step - loss: 0.3483 - auc: 0.9686 - Precision: 0.8576 - Recall: 0.8506 - categorical_accuracy: 0.8555 - val_loss: 1.1116 - val_auc: 0.8325 - val_Precision: 0.6316 - val_Recall: 0.6316 - val_categorical_accuracy: 0.6316\n",
      "Epoch 33/200\n",
      "153/153 [==============================] - 242s 2s/step - loss: 0.3210 - auc: 0.9719 - Precision: 0.8764 - Recall: 0.8736 - categorical_accuracy: 0.8768 - val_loss: 0.9915 - val_auc: 0.8304 - val_Precision: 0.6575 - val_Recall: 0.6316 - val_categorical_accuracy: 0.6579\n",
      "Epoch 34/200\n",
      "153/153 [==============================] - 242s 2s/step - loss: 0.2912 - auc: 0.9786 - Precision: 0.8766 - Recall: 0.8752 - categorical_accuracy: 0.8752 - val_loss: 1.2778 - val_auc: 0.8165 - val_Precision: 0.6467 - val_Recall: 0.6382 - val_categorical_accuracy: 0.6447\n",
      "Epoch 35/200\n",
      "153/153 [==============================] - 246s 2s/step - loss: 0.3241 - auc: 0.9714 - Precision: 0.8630 - Recall: 0.8588 - categorical_accuracy: 0.8621 - val_loss: 1.0275 - val_auc: 0.8336 - val_Precision: 0.6554 - val_Recall: 0.6382 - val_categorical_accuracy: 0.6382\n",
      "Epoch 36/200\n",
      "153/153 [==============================] - 244s 2s/step - loss: 0.2629 - auc: 0.9832 - Precision: 0.8861 - Recall: 0.8818 - categorical_accuracy: 0.8851 - val_loss: 1.0980 - val_auc: 0.8276 - val_Precision: 0.6419 - val_Recall: 0.6250 - val_categorical_accuracy: 0.6316\n",
      "Epoch 37/200\n",
      "153/153 [==============================] - 247s 2s/step - loss: 0.2681 - auc: 0.9809 - Precision: 0.8882 - Recall: 0.8867 - categorical_accuracy: 0.8867 - val_loss: 1.0384 - val_auc: 0.8286 - val_Precision: 0.6447 - val_Recall: 0.6447 - val_categorical_accuracy: 0.6447\n",
      "Epoch 38/200\n",
      "153/153 [==============================] - 242s 2s/step - loss: 0.2473 - auc: 0.9851 - Precision: 0.8987 - Recall: 0.8883 - categorical_accuracy: 0.8966 - val_loss: 1.0285 - val_auc: 0.8012 - val_Precision: 0.6225 - val_Recall: 0.6184 - val_categorical_accuracy: 0.6250\n",
      "Epoch 39/200\n",
      "153/153 [==============================] - 242s 2s/step - loss: 0.2375 - auc: 0.9853 - Precision: 0.8980 - Recall: 0.8966 - categorical_accuracy: 0.8966 - val_loss: 1.1650 - val_auc: 0.8120 - val_Precision: 0.6358 - val_Recall: 0.6316 - val_categorical_accuracy: 0.6316\n",
      "Epoch 40/200\n",
      " 21/153 [===>..........................] - ETA: 3:13 - loss: 0.1891 - auc: 0.9928 - Precision: 0.9036 - Recall: 0.8929 - categorical_accuracy: 0.8929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "the_metrics=[tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name=\"Precision\"), tf.keras.metrics.Recall(name=\"Recall\"),tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer = keras.optimizers.AdamW(learning_rate=5e-5,weight_decay=1e-4),\n",
    "    metrics = the_metrics   \n",
    ")\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',patience = 20, verbose = 1, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(\n",
    "    dg_train,\n",
    "    validation_data = dg_val,\n",
    "    epochs = 200,\n",
    "    verbose = 1,\n",
    "    callbacks = [early]\n",
    ")\n",
    "model.save('/lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/T1andDWIwithoutImp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00eb1269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/T1andDWIwithoutImp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf8cddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14207/2532890018.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n",
      "2023-11-12 12:20:16.929556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 21s 529ms/step - loss: 0.8686 - auc: 0.7757 - Precision: 0.5874 - Recall: 0.5419 - categorical_accuracy: 0.5742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8686206340789795,\n",
       " 0.7757439613342285,\n",
       " 0.5874125957489014,\n",
       " 0.5419355034828186,\n",
       " 0.57419353723526]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dg_testall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d624c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4355bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28813/2532890018.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n",
      "2023-11-16 12:34:00.237482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 1s 627ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for img,lbl in dg_testall:\n",
    "    for i in lbl:\n",
    "        y_true.append(i)\n",
    "    x = model.predict(img)\n",
    "    for i in x:\n",
    "        y_pred.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d83554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b88e45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = np.argmax(y_true,1)\n",
    "yp = np.argmax(y_pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10016d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5741935483870968"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = skm.accuracy_score(yt,yp)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f27c5645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40657590956134065"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_acc = skm.balanced_accuracy_score(yt,yp)\n",
    "bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84cb5a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7754630593132154"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_auc = skm.roc_auc_score(yt,y_pred,average='micro',multi_class='ovr')\n",
    "mic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6f743a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7133094044506398"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mac_auc = skm.roc_auc_score(yt,y_pred,average='macro',multi_class='ovr')\n",
    "mac_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d67245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# IMPUTATION TECHNIQUE 0 ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fcdb50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneratorImpT1(tf.keras.utils.Sequence):\n",
    "    def rotate(self,vol):\n",
    "        def scipy_rotate(vol):\n",
    "            angles = [-20,-10,-5,0,5,10,20]\n",
    "            angle = pyrandom.choice(angles)\n",
    "            vol = ndimage.rotate(vol,angle,reshape=False)\n",
    "            vol[vol<0] = 0\n",
    "            vol[vol>1] = 1\n",
    "            return vol\n",
    "        aug_vol = tf.numpy_function(scipy_rotate,[vol],tf.float32)\n",
    "        return aug_vol\n",
    "\n",
    "    def preprocessing(self,vol):\n",
    "        if(self.isTrain):\n",
    "            vol1 = self.rotate(vol)\n",
    "            vol1 = tf.expand_dims(vol1,axis=3)\n",
    "        else:\n",
    "            vol1 = tf.expand_dims(vol,axis=3)\n",
    "        return vol1\n",
    "    \n",
    "    def read_scan(self,path):\n",
    "        scan = nib.load(path)\n",
    "        volume = scan.get_fdata()\n",
    "        min = np.amax(volume)\n",
    "        max = np.amin(volume)\n",
    "        volume = (volume - min) / (max - min)\n",
    "        volume = volume.astype(\"float32\")\n",
    "        return volume\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (np.floor(len(self.data) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "    def __init__(self,data, batch_size, sample_weights=None,isTrain=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_weights = sample_weights\n",
    "        self.isTrain = isTrain\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t1  = self.data['ACCEL_DL_6DOF_2MM_T1'].tolist()\n",
    "        dwi = self.data['DWI_Matched_File_FA_Path_ENIGMATBSSspace_2MM'].tolist()\n",
    "        labels = self.data['DX']\n",
    "        labels = keras.utils.to_categorical(labels)\n",
    "        \n",
    "        batch_t1 = t1[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_dwi = dwi[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_y = labels[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        t1_imgs = np.asarray([self.preprocessing(self.read_scan(path)) for path in batch_t1])\n",
    "        dwi = []\n",
    "        for i in batch_dwi:\n",
    "            if pd.isnull(i):\n",
    "                dwi.append(avgMRI)\n",
    "            else:\n",
    "                dwi.append((self.read_scan(i)))\n",
    "        dwi_imgs = np.asarray([self.preprocessing(img) for img in dwi])\n",
    "        return ([t1_imgs,dwi_imgs], np.array(batch_y))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if(self.isTrain):\n",
    "            self.data = self.data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8bedc456",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_dwi = df.loc[[(not condt1[i] and conddwi[i]) for i in range(len(condt1))] , :]\n",
    "avg = [t1_dwi,trainds]\n",
    "avgCN = pd.concat(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1c2666d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avgCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "665c4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in avgCN['SubjID'].drop_duplicates():\n",
    "    for j in testall['SubjID'].drop_duplicates():\n",
    "        if i == j:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ac143da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCN.drop(avgCN[(avgCN['SubjID']=='141_S_1378') ].index,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cf00a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scan(path):\n",
    "        scan = nib.load(path)\n",
    "        volume = scan.get_fdata()\n",
    "        return volume\n",
    "def normalize(vol):\n",
    "    min = np.amax(vol)\n",
    "    max = np.amin(vol)\n",
    "    vol = (vol-min) / (max-min)\n",
    "    vol = vol.astype('float32')\n",
    "    return vol\n",
    "\n",
    "avgMRI = np.zeros((91,109,91))\n",
    "\n",
    "for i in avgCN['DWI_Matched_File_FA_Path_ENIGMATBSSspace_2MM']:\n",
    "    avgMRI += read_scan(i)\n",
    "    \n",
    "avgMRI = normalize(avgMRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e706e0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 609)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainds),len(alltrain[:p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "79e318c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1dwi_ = df.loc[[(condt1[i] and not conddwi[i]) for i in range(len(condt1))] , :]\n",
    "train1 = [t1dwi_,trainds]\n",
    "train1 = pd.concat(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "85f029b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4685"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1dwi_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1d438cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "arr = []\n",
    "for i in train1['SubjID'].drop_duplicates():\n",
    "    for j in testall['SubjID'].drop_duplicates():\n",
    "        if i == j:\n",
    "            arr.append(i)\n",
    "            count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f1b43854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in arr:\n",
    "    train1.drop(train1[(train1['SubjID']==i) ].index,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7ae7d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train1['SubjID'].drop_duplicates():\n",
    "    for j in testall['SubjID'].drop_duplicates():\n",
    "        if i == j:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "362d5e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4828"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c6dcd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg1_train = DataGeneratorImpT1(train1,batch_size)\n",
    "dg_val = DataGenerator(valds,batch_size,isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2537f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/T1andDWIwithoutImp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c3361a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5022/2532890018.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5022/683972216.py:31: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.floor(len(self.data) / float(self.batch_size))).astype(np.int)\n",
      "2023-11-21 15:27:48.544882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207/1207 [==============================] - ETA: 0s - loss: 0.6772 - auc: 0.8732 - Precision: 0.7229 - Recall: 0.6607 - categorical_accuracy: 0.7065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 15:58:13.428116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207/1207 [==============================] - 1841s 2s/step - loss: 0.6772 - auc: 0.8732 - Precision: 0.7229 - Recall: 0.6607 - categorical_accuracy: 0.7065 - val_loss: 0.7004 - val_auc: 0.8599 - val_Precision: 0.6803 - val_Recall: 0.6579 - val_categorical_accuracy: 0.6776\n",
      "Epoch 2/300\n",
      "1207/1207 [==============================] - 1854s 2s/step - loss: 0.6095 - auc: 0.8960 - Precision: 0.7492 - Recall: 0.7171 - categorical_accuracy: 0.7388 - val_loss: 0.7509 - val_auc: 0.8392 - val_Precision: 0.6597 - val_Recall: 0.6250 - val_categorical_accuracy: 0.6447\n",
      "Epoch 3/300\n",
      "1207/1207 [==============================] - 1826s 2s/step - loss: 0.5505 - auc: 0.9153 - Precision: 0.7759 - Recall: 0.7601 - categorical_accuracy: 0.7715 - val_loss: 0.8308 - val_auc: 0.8438 - val_Precision: 0.7007 - val_Recall: 0.6776 - val_categorical_accuracy: 0.6842\n",
      "Epoch 4/300\n",
      "1207/1207 [==============================] - 1815s 2s/step - loss: 0.4969 - auc: 0.9314 - Precision: 0.8068 - Recall: 0.7985 - categorical_accuracy: 0.8047 - val_loss: 0.8835 - val_auc: 0.8568 - val_Precision: 0.6867 - val_Recall: 0.6776 - val_categorical_accuracy: 0.6842\n",
      "Epoch 5/300\n",
      "1207/1207 [==============================] - 1828s 2s/step - loss: 0.4587 - auc: 0.9410 - Precision: 0.8205 - Recall: 0.8140 - categorical_accuracy: 0.8165 - val_loss: 0.8368 - val_auc: 0.8294 - val_Precision: 0.6533 - val_Recall: 0.6447 - val_categorical_accuracy: 0.6513\n",
      "Epoch 6/300\n",
      "1207/1207 [==============================] - 1842s 2s/step - loss: 0.4242 - auc: 0.9491 - Precision: 0.8390 - Recall: 0.8322 - categorical_accuracy: 0.8360 - val_loss: 0.9100 - val_auc: 0.8047 - val_Precision: 0.6093 - val_Recall: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 7/300\n",
      "1207/1207 [==============================] - 1857s 2s/step - loss: 0.3861 - auc: 0.9575 - Precision: 0.8589 - Recall: 0.8560 - categorical_accuracy: 0.8579 - val_loss: 0.9603 - val_auc: 0.7981 - val_Precision: 0.5762 - val_Recall: 0.5724 - val_categorical_accuracy: 0.5724\n",
      "Epoch 8/300\n",
      "1207/1207 [==============================] - 1850s 2s/step - loss: 0.3324 - auc: 0.9682 - Precision: 0.8820 - Recall: 0.8795 - categorical_accuracy: 0.8805 - val_loss: 0.9647 - val_auc: 0.8421 - val_Precision: 0.6424 - val_Recall: 0.6382 - val_categorical_accuracy: 0.6382\n",
      "Epoch 9/300\n",
      "1207/1207 [==============================] - 1858s 2s/step - loss: 0.3154 - auc: 0.9707 - Precision: 0.8875 - Recall: 0.8855 - categorical_accuracy: 0.8869 - val_loss: 0.9622 - val_auc: 0.8356 - val_Precision: 0.6490 - val_Recall: 0.6447 - val_categorical_accuracy: 0.6513\n",
      "Epoch 10/300\n",
      "1207/1207 [==============================] - 1802s 1s/step - loss: 0.2884 - auc: 0.9748 - Precision: 0.9012 - Recall: 0.8993 - categorical_accuracy: 0.9000 - val_loss: 1.1103 - val_auc: 0.7815 - val_Precision: 0.5921 - val_Recall: 0.5921 - val_categorical_accuracy: 0.5921\n",
      "Epoch 11/300\n",
      "1207/1207 [==============================] - 1848s 2s/step - loss: 0.2655 - auc: 0.9788 - Precision: 0.9043 - Recall: 0.9027 - categorical_accuracy: 0.9037 - val_loss: 0.9826 - val_auc: 0.8447 - val_Precision: 0.6513 - val_Recall: 0.6513 - val_categorical_accuracy: 0.6513\n",
      "Epoch 12/300\n",
      "1207/1207 [==============================] - 1863s 2s/step - loss: 0.2538 - auc: 0.9805 - Precision: 0.9084 - Recall: 0.9053 - categorical_accuracy: 0.9068 - val_loss: 0.9682 - val_auc: 0.8253 - val_Precision: 0.6447 - val_Recall: 0.6447 - val_categorical_accuracy: 0.6447\n",
      "Epoch 13/300\n",
      "1207/1207 [==============================] - 1795s 1s/step - loss: 0.2486 - auc: 0.9810 - Precision: 0.9122 - Recall: 0.9105 - categorical_accuracy: 0.9114 - val_loss: 0.9353 - val_auc: 0.8371 - val_Precision: 0.6467 - val_Recall: 0.6382 - val_categorical_accuracy: 0.6513\n",
      "Epoch 14/300\n",
      "1207/1207 [==============================] - 1788s 1s/step - loss: 0.2254 - auc: 0.9841 - Precision: 0.9236 - Recall: 0.9215 - categorical_accuracy: 0.9227 - val_loss: 1.3685 - val_auc: 0.7219 - val_Precision: 0.4868 - val_Recall: 0.4868 - val_categorical_accuracy: 0.4868\n",
      "Epoch 15/300\n",
      "1207/1207 [==============================] - 1761s 1s/step - loss: 0.2099 - auc: 0.9864 - Precision: 0.9275 - Recall: 0.9246 - categorical_accuracy: 0.9263 - val_loss: 1.2524 - val_auc: 0.7398 - val_Precision: 0.5000 - val_Recall: 0.5000 - val_categorical_accuracy: 0.5000\n",
      "Epoch 16/300\n",
      "1207/1207 [==============================] - 1791s 1s/step - loss: 0.1905 - auc: 0.9886 - Precision: 0.9344 - Recall: 0.9327 - categorical_accuracy: 0.9335 - val_loss: 1.2253 - val_auc: 0.7803 - val_Precision: 0.5987 - val_Recall: 0.5987 - val_categorical_accuracy: 0.5987\n",
      "Epoch 17/300\n",
      "1207/1207 [==============================] - 1844s 2s/step - loss: 0.1848 - auc: 0.9888 - Precision: 0.9357 - Recall: 0.9339 - categorical_accuracy: 0.9348 - val_loss: 1.2431 - val_auc: 0.8202 - val_Precision: 0.6358 - val_Recall: 0.6316 - val_categorical_accuracy: 0.6316\n",
      "Epoch 18/300\n",
      "1207/1207 [==============================] - 1809s 1s/step - loss: 0.1845 - auc: 0.9893 - Precision: 0.9365 - Recall: 0.9348 - categorical_accuracy: 0.9352 - val_loss: 1.1774 - val_auc: 0.8068 - val_Precision: 0.6319 - val_Recall: 0.5987 - val_categorical_accuracy: 0.6316\n",
      "Epoch 19/300\n",
      "1207/1207 [==============================] - 1854s 2s/step - loss: 0.1694 - auc: 0.9902 - Precision: 0.9447 - Recall: 0.9420 - categorical_accuracy: 0.9437 - val_loss: 1.4865 - val_auc: 0.7368 - val_Precision: 0.5306 - val_Recall: 0.5132 - val_categorical_accuracy: 0.5263\n",
      "Epoch 20/300\n",
      "1207/1207 [==============================] - 1821s 2s/step - loss: 0.1636 - auc: 0.9910 - Precision: 0.9448 - Recall: 0.9437 - categorical_accuracy: 0.9437 - val_loss: 1.1112 - val_auc: 0.8368 - val_Precision: 0.6358 - val_Recall: 0.6316 - val_categorical_accuracy: 0.6382\n",
      "Epoch 21/300\n",
      "1207/1207 [==============================] - 1832s 2s/step - loss: 0.1584 - auc: 0.9916 - Precision: 0.9486 - Recall: 0.9474 - categorical_accuracy: 0.9480 - val_loss: 1.1347 - val_auc: 0.8089 - val_Precision: 0.6267 - val_Recall: 0.6184 - val_categorical_accuracy: 0.6184\n",
      "Epoch 22/300\n",
      "1207/1207 [==============================] - 1883s 2s/step - loss: 0.1519 - auc: 0.9923 - Precision: 0.9462 - Recall: 0.9435 - categorical_accuracy: 0.9451 - val_loss: 1.2505 - val_auc: 0.8197 - val_Precision: 0.6667 - val_Recall: 0.6579 - val_categorical_accuracy: 0.6579\n",
      "Epoch 23/300\n",
      "1207/1207 [==============================] - 1864s 2s/step - loss: 0.1436 - auc: 0.9928 - Precision: 0.9515 - Recall: 0.9501 - categorical_accuracy: 0.9511 - val_loss: 1.2036 - val_auc: 0.8302 - val_Precision: 0.6755 - val_Recall: 0.6711 - val_categorical_accuracy: 0.6711\n",
      "Epoch 24/300\n",
      "1207/1207 [==============================] - 1872s 2s/step - loss: 0.1319 - auc: 0.9939 - Precision: 0.9556 - Recall: 0.9548 - categorical_accuracy: 0.9551 - val_loss: 1.2881 - val_auc: 0.7846 - val_Precision: 0.5333 - val_Recall: 0.5263 - val_categorical_accuracy: 0.5263\n",
      "Epoch 25/300\n",
      "1207/1207 [==============================] - 1845s 2s/step - loss: 0.1354 - auc: 0.9941 - Precision: 0.9554 - Recall: 0.9530 - categorical_accuracy: 0.9534 - val_loss: 1.2786 - val_auc: 0.7922 - val_Precision: 0.5473 - val_Recall: 0.5329 - val_categorical_accuracy: 0.5461\n",
      "Epoch 26/300\n",
      "1207/1207 [==============================] - 1863s 2s/step - loss: 0.1229 - auc: 0.9950 - Precision: 0.9577 - Recall: 0.9559 - categorical_accuracy: 0.9565 - val_loss: 1.3504 - val_auc: 0.7799 - val_Precision: 0.5533 - val_Recall: 0.5461 - val_categorical_accuracy: 0.5526\n",
      "Epoch 27/300\n",
      "1207/1207 [==============================] - 1840s 2s/step - loss: 0.1261 - auc: 0.9939 - Precision: 0.9600 - Recall: 0.9592 - categorical_accuracy: 0.9594 - val_loss: 1.2844 - val_auc: 0.7758 - val_Precision: 0.5333 - val_Recall: 0.5263 - val_categorical_accuracy: 0.5263\n",
      "Epoch 28/300\n",
      "1207/1207 [==============================] - 1862s 2s/step - loss: 0.1108 - auc: 0.9956 - Precision: 0.9649 - Recall: 0.9633 - categorical_accuracy: 0.9638 - val_loss: 1.1063 - val_auc: 0.8240 - val_Precision: 0.6645 - val_Recall: 0.6645 - val_categorical_accuracy: 0.6645\n",
      "Epoch 29/300\n",
      "1207/1207 [==============================] - 1874s 2s/step - loss: 0.1073 - auc: 0.9961 - Precision: 0.9629 - Recall: 0.9615 - categorical_accuracy: 0.9621 - val_loss: 1.3989 - val_auc: 0.7970 - val_Precision: 0.6358 - val_Recall: 0.6316 - val_categorical_accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/300\n",
      "1207/1207 [==============================] - 1749s 1s/step - loss: 0.1143 - auc: 0.9948 - Precision: 0.9616 - Recall: 0.9600 - categorical_accuracy: 0.9609 - val_loss: 1.3353 - val_auc: 0.7793 - val_Precision: 0.5772 - val_Recall: 0.5658 - val_categorical_accuracy: 0.5789\n",
      "Epoch 31/300\n",
      "1207/1207 [==============================] - ETA: 0s - loss: 0.0961 - auc: 0.9967 - Precision: 0.9660 - Recall: 0.9650 - categorical_accuracy: 0.9654Restoring model weights from the end of the best epoch: 1.\n",
      "1207/1207 [==============================] - 1728s 1s/step - loss: 0.0961 - auc: 0.9967 - Precision: 0.9660 - Recall: 0.9650 - categorical_accuracy: 0.9654 - val_loss: 2.3024 - val_auc: 0.6264 - val_Precision: 0.3826 - val_Recall: 0.3750 - val_categorical_accuracy: 0.3750\n",
      "Epoch 31: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 07:13:51.310866: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,1,1,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-11-22 07:13:51.321116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,1,1,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-11-22 07:13:53.096332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,1,1,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-11-22 07:13:53.120070: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,1,1,64]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/XT1andDWIAvgImp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/XT1andDWIAvgImp/assets\n"
     ]
    }
   ],
   "source": [
    "filepath = '/lfs1/ashaji/Imputation_Problem/further/IMPT1andDWI/modelIMPT1andDWI-epoch{epoch:02d}-val_loss{val_loss:.2f}'\n",
    "check = keras.callbacks.ModelCheckpoint(filepath,monitor='val_loss',verbose=1,save_best_only=True,mode='auto')\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',patience = 30, verbose = 1, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(\n",
    "    dg1_train,\n",
    "    validation_data = dg_val,\n",
    "    epochs = 300,\n",
    "    verbose = 1,\n",
    "    callbacks = [early]\n",
    ")\n",
    "model.save('/lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/XT1andDWIAvgImp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "72259207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5022/2532890018.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n",
      "2023-11-21 15:06:28.685483: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 17s 425ms/step - loss: 0.8081 - auc: 0.7991 - Precision: 0.6015 - Recall: 0.5161 - categorical_accuracy: 0.5613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8080710768699646,\n",
       " 0.7991362810134888,\n",
       " 0.6015037298202515,\n",
       " 0.5161290168762207,\n",
       " 0.5612903237342834]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dg_testall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "903af127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "85ae96c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5022/2532890018.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for img,lbl in dg_testall:\n",
    "    for i in lbl:\n",
    "        y_true.append(i)\n",
    "    x = model.predict(img)\n",
    "    for i in x:\n",
    "        y_pred.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "19e4107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6c5bd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = np.argmax(y_true,1)\n",
    "yp = np.argmax(y_pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4256fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6129032258064516"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = skm.accuracy_score(yt,yp)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cfccc633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.534625808662423"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_acc = skm.balanced_accuracy_score(yt,yp)\n",
    "bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3e511d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115296566077003"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_auc = skm.roc_auc_score(yt,y_pred,average='micro',multi_class='ovr')\n",
    "mic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "622f68db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7432584926039884"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mac_auc = skm.roc_auc_score(yt,y_pred,average='macro',multi_class='ovr')\n",
    "mac_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPUTATION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scan(path):\n",
    "        scan = nib.load(str(path))\n",
    "        volume = scan.get_fdata()\n",
    "        return volume\n",
    "def normalize(vol):\n",
    "    min = np.amax(vol)\n",
    "    max = np.amin(vol)\n",
    "    if max == 0 and min == 0:\n",
    "        return vol\n",
    "    vol = (vol-min) / (max-min)\n",
    "    vol = vol.astype('float32')\n",
    "    return vol\n",
    "\n",
    "def avgMRI(avg):  \n",
    "    avgMRI = np.zeros((91,109,91))\n",
    "    if avg.empty:\n",
    "        return avgMRI\n",
    "    for i in avg['DWI_Matched_File_FA_Path_ENIGMATBSSspace_2MM']:\n",
    "        avgMRI += read_scan(i)\n",
    "    return normalize(avgMRI)\n",
    "\n",
    "avg0 = avgCN[(avgCN['AGE_at_scan'] >= 40) & (avgCN['AGE_at_scan'] < 45)]\n",
    "avg1 = avgCN[(avgCN['AGE_at_scan'] >= 45) & (avgCN['AGE_at_scan'] < 50)]\n",
    "avg2 = avgCN[(avgCN['AGE_at_scan'] >= 50) & (avgCN['AGE_at_scan'] < 55)]\n",
    "avg3 = avgCN[(avgCN['AGE_at_scan'] >= 55) & (avgCN['AGE_at_scan'] < 60)]\n",
    "avg4 = avgCN[(avgCN['AGE_at_scan'] >= 60) & (avgCN['AGE_at_scan'] < 65)]\n",
    "avg5 = avgCN[(avgCN['AGE_at_scan'] >= 65) & (avgCN['AGE_at_scan'] < 70)]\n",
    "avg6 = avgCN[(avgCN['AGE_at_scan'] >= 70) & (avgCN['AGE_at_scan'] < 75)]\n",
    "avg7 = avgCN[(avgCN['AGE_at_scan'] >= 75) & (avgCN['AGE_at_scan'] < 80)]\n",
    "avg8 = avgCN[(avgCN['AGE_at_scan'] >= 80) & (avgCN['AGE_at_scan'] < 85)]\n",
    "avg9 = avgCN[(avgCN['AGE_at_scan'] >= 85) & (avgCN['AGE_at_scan'] < 90)]\n",
    "avg10 = avgCN[(avgCN['AGE_at_scan'] >= 90) & (avgCN['AGE_at_scan'] < 95)]\n",
    "avg11 = avgCN[(avgCN['AGE_at_scan'] >= 95) & (avgCN['AGE_at_scan'] < 100)]\n",
    "avg0 = avgMRI(avg0)\n",
    "avg1 = avgMRI(avg1)\n",
    "avg2 = avgMRI(avg2)\n",
    "avg3 = avgMRI(avg3)\n",
    "avg4 = avgMRI(avg4)\n",
    "avg5 = avgMRI(avg5)\n",
    "avg6 = avgMRI(avg6)\n",
    "avg7 = avgMRI(avg7)\n",
    "avg8 = avgMRI(avg8)\n",
    "avg9 = avgMRI(avg9)\n",
    "avg10 = avgMRI(avg10)\n",
    "avg11 = avgMRI(avg11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ecbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneratorMRIs(tf.keras.utils.Sequence):\n",
    "    def rotate(self,vol):\n",
    "        def scipy_rotate(vol):\n",
    "            angles = [-20,-10,-5,0,5,10,20]\n",
    "            angle = pyrandom.choice(angles)\n",
    "            vol = ndimage.rotate(vol,angle,reshape=False)\n",
    "            vol[vol<0] = 0\n",
    "            vol[vol>1] = 1\n",
    "            return vol\n",
    "        aug_vol = tf.numpy_function(scipy_rotate,[vol],tf.float32)\n",
    "        return aug_vol\n",
    "\n",
    "    def preprocessing(self,vol):\n",
    "        vol1 = self.rotate(vol)\n",
    "        vol1 = tf.expand_dims(vol1,axis=3)\n",
    "        return vol1\n",
    "    \n",
    "    def returnAvg(self,age):\n",
    "        if age>=40 and age < 45:\n",
    "            return avg0\n",
    "        elif age>=45 and age < 50:\n",
    "            return avg1\n",
    "        elif age>=50 and age < 55:\n",
    "            return avg2\n",
    "        elif age>=55 and age < 60:\n",
    "            return avg3\n",
    "        elif age>=60 and age < 65:\n",
    "            return avg4\n",
    "        elif age>=65 and age < 70:\n",
    "            return avg5\n",
    "        elif age>=70 and age < 75:\n",
    "            return avg6\n",
    "        elif age>=75 and age < 80:\n",
    "            return avg7\n",
    "        elif age>=80 and age < 85:\n",
    "            return avg8\n",
    "        elif age>=85 and age < 90:\n",
    "            return avg9\n",
    "        elif age>=90 and age < 95:\n",
    "            return avg10\n",
    "        elif age>=95 and age < 100:\n",
    "            return avg11\n",
    "        \n",
    "    \n",
    "    def read_scan(self,path):\n",
    "        scan = nib.load(path)\n",
    "        volume = scan.get_fdata()\n",
    "        min = np.amax(volume)\n",
    "        max = np.amin(volume)\n",
    "        volume = (volume - min) / (max - min)\n",
    "        volume = volume.astype(\"float32\")\n",
    "        return volume\n",
    "\n",
    "    def __init__(self,data, batch_size, sample_weights=None):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_weights = sample_weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        t1  = self.data['ACCEL_DL_6DOF_2MM_T1'].tolist()\n",
    "        dwi = self.data['DWI_Matched_File_FA_Path_ENIGMATBSSspace_2MM'].tolist()\n",
    "        labels = self.data['AGE_at_scan'].astype(np.float32)\n",
    "        labelsx = self.data['DX']\n",
    "        labelsx = keras.utils.to_categorical(labelsx)\n",
    "        \n",
    "        batch_t1 = t1[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_y = labels[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_x = labelsx[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_dwi = dwi[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        \n",
    "        dwi = []\n",
    "        for i in range(len(batch_dwi)):\n",
    "            if pd.isnull(batch_dwi[i]):\n",
    "                dwi.append(self.returnAvg(batch_y.iloc[i]))\n",
    "            else:\n",
    "                dwi.append((self.read_scan(batch_dwi[i])))\n",
    "                \n",
    "        t1_imgs = np.asarray([self.preprocessing(self.read_scan(path)) for path in batch_t1])\n",
    "        dwi_imgs = np.asarray([self.preprocessing(img) for img in dwi])\n",
    "        \n",
    "        return ([t1_imgs,dwi_imgs], np.array(batch_x))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.data = self.data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc543a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg2_train = DataGeneratorMRIs(train1,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dc1520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/T1andDWIBuckImp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f36c5624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30762/2532890018.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30762/2577338316.py:60: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n",
      "2023-11-19 02:54:08.091085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324/1324 [==============================] - ETA: 0s - loss: 0.3277 - auc: 0.9682 - Precision: 0.8821 - Recall: 0.8806 - categorical_accuracy: 0.8819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 03:32:07.101831: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324/1324 [==============================] - 2306s 2s/step - loss: 0.3277 - auc: 0.9682 - Precision: 0.8821 - Recall: 0.8806 - categorical_accuracy: 0.8819 - val_loss: 0.7085 - val_auc: 0.8853 - val_Precision: 0.7267 - val_Recall: 0.7171 - val_categorical_accuracy: 0.7171\n",
      "Epoch 2/200\n",
      "1324/1324 [==============================] - 1923s 1s/step - loss: 0.2915 - auc: 0.9746 - Precision: 0.8971 - Recall: 0.8961 - categorical_accuracy: 0.8969 - val_loss: 0.7390 - val_auc: 0.8893 - val_Precision: 0.7434 - val_Recall: 0.7434 - val_categorical_accuracy: 0.7434\n",
      "Epoch 3/200\n",
      "1324/1324 [==============================] - 1928s 1s/step - loss: 0.2602 - auc: 0.9789 - Precision: 0.9073 - Recall: 0.9063 - categorical_accuracy: 0.9069 - val_loss: 0.8999 - val_auc: 0.8724 - val_Precision: 0.7105 - val_Recall: 0.7105 - val_categorical_accuracy: 0.7105\n",
      "Epoch 4/200\n",
      "1324/1324 [==============================] - 1923s 1s/step - loss: 0.2545 - auc: 0.9795 - Precision: 0.9108 - Recall: 0.9103 - categorical_accuracy: 0.9108 - val_loss: 0.7794 - val_auc: 0.8899 - val_Precision: 0.7400 - val_Recall: 0.7303 - val_categorical_accuracy: 0.7303\n",
      "Epoch 5/200\n",
      "1324/1324 [==============================] - 1913s 1s/step - loss: 0.2292 - auc: 0.9834 - Precision: 0.9210 - Recall: 0.9201 - categorical_accuracy: 0.9205 - val_loss: 0.6884 - val_auc: 0.8965 - val_Precision: 0.7303 - val_Recall: 0.7303 - val_categorical_accuracy: 0.7303\n",
      "Epoch 6/200\n",
      "1324/1324 [==============================] - 1920s 1s/step - loss: 0.2202 - auc: 0.9844 - Precision: 0.9258 - Recall: 0.9244 - categorical_accuracy: 0.9250 - val_loss: 0.8971 - val_auc: 0.8436 - val_Precision: 0.6447 - val_Recall: 0.6447 - val_categorical_accuracy: 0.6447\n",
      "Epoch 7/200\n",
      "1324/1324 [==============================] - 1907s 1s/step - loss: 0.2109 - auc: 0.9861 - Precision: 0.9246 - Recall: 0.9239 - categorical_accuracy: 0.9244 - val_loss: 0.7444 - val_auc: 0.8961 - val_Precision: 0.7333 - val_Recall: 0.7237 - val_categorical_accuracy: 0.7303\n",
      "Epoch 8/200\n",
      "1324/1324 [==============================] - 1906s 1s/step - loss: 0.1889 - auc: 0.9889 - Precision: 0.9347 - Recall: 0.9335 - categorical_accuracy: 0.9339 - val_loss: 0.9185 - val_auc: 0.8516 - val_Precision: 0.6490 - val_Recall: 0.6447 - val_categorical_accuracy: 0.6447\n",
      "Epoch 9/200\n",
      "1324/1324 [==============================] - 1906s 1s/step - loss: 0.1741 - auc: 0.9898 - Precision: 0.9402 - Recall: 0.9392 - categorical_accuracy: 0.9396 - val_loss: 0.8734 - val_auc: 0.8765 - val_Precision: 0.7105 - val_Recall: 0.7105 - val_categorical_accuracy: 0.7105\n",
      "Epoch 10/200\n",
      "1324/1324 [==============================] - 1915s 1s/step - loss: 0.1764 - auc: 0.9895 - Precision: 0.9402 - Recall: 0.9380 - categorical_accuracy: 0.9388 - val_loss: 0.8453 - val_auc: 0.8730 - val_Precision: 0.6689 - val_Recall: 0.6645 - val_categorical_accuracy: 0.6711\n",
      "Epoch 11/200\n",
      "1324/1324 [==============================] - 1908s 1s/step - loss: 0.1693 - auc: 0.9906 - Precision: 0.9434 - Recall: 0.9420 - categorical_accuracy: 0.9431 - val_loss: 0.8397 - val_auc: 0.8851 - val_Precision: 0.7303 - val_Recall: 0.7303 - val_categorical_accuracy: 0.7303\n",
      "Epoch 12/200\n",
      "1324/1324 [==============================] - 1912s 1s/step - loss: 0.1671 - auc: 0.9910 - Precision: 0.9412 - Recall: 0.9409 - categorical_accuracy: 0.9409 - val_loss: 0.7295 - val_auc: 0.8798 - val_Precision: 0.7181 - val_Recall: 0.7039 - val_categorical_accuracy: 0.7237\n",
      "Epoch 13/200\n",
      "1324/1324 [==============================] - 1871s 1s/step - loss: 0.1447 - auc: 0.9928 - Precision: 0.9512 - Recall: 0.9503 - categorical_accuracy: 0.9509 - val_loss: 0.8792 - val_auc: 0.8825 - val_Precision: 0.7067 - val_Recall: 0.6974 - val_categorical_accuracy: 0.7039\n",
      "Epoch 14/200\n",
      "1324/1324 [==============================] - 1883s 1s/step - loss: 0.1502 - auc: 0.9922 - Precision: 0.9488 - Recall: 0.9477 - categorical_accuracy: 0.9479 - val_loss: 0.7900 - val_auc: 0.8898 - val_Precision: 0.7285 - val_Recall: 0.7237 - val_categorical_accuracy: 0.7237\n",
      "Epoch 15/200\n",
      "1324/1324 [==============================] - 1887s 1s/step - loss: 0.1539 - auc: 0.9922 - Precision: 0.9480 - Recall: 0.9464 - categorical_accuracy: 0.9469 - val_loss: 0.8994 - val_auc: 0.8704 - val_Precision: 0.6755 - val_Recall: 0.6711 - val_categorical_accuracy: 0.6776\n",
      "Epoch 16/200\n",
      "1324/1324 [==============================] - 1887s 1s/step - loss: 0.1287 - auc: 0.9937 - Precision: 0.9587 - Recall: 0.9569 - categorical_accuracy: 0.9577 - val_loss: 0.9580 - val_auc: 0.8851 - val_Precision: 0.7285 - val_Recall: 0.7237 - val_categorical_accuracy: 0.7237\n",
      "Epoch 17/200\n",
      "1324/1324 [==============================] - 1875s 1s/step - loss: 0.1281 - auc: 0.9940 - Precision: 0.9582 - Recall: 0.9579 - categorical_accuracy: 0.9581 - val_loss: 0.8820 - val_auc: 0.8667 - val_Precision: 0.6974 - val_Recall: 0.6974 - val_categorical_accuracy: 0.6974\n",
      "Epoch 18/200\n",
      "1324/1324 [==============================] - 1874s 1s/step - loss: 0.1255 - auc: 0.9943 - Precision: 0.9584 - Recall: 0.9573 - categorical_accuracy: 0.9577 - val_loss: 0.8273 - val_auc: 0.8765 - val_Precision: 0.7237 - val_Recall: 0.7237 - val_categorical_accuracy: 0.7237\n",
      "Epoch 19/200\n",
      "1324/1324 [==============================] - 1879s 1s/step - loss: 0.1214 - auc: 0.9946 - Precision: 0.9612 - Recall: 0.9603 - categorical_accuracy: 0.9603 - val_loss: 0.7827 - val_auc: 0.8902 - val_Precision: 0.7133 - val_Recall: 0.7039 - val_categorical_accuracy: 0.7105\n",
      "Epoch 20/200\n",
      "1324/1324 [==============================] - 1872s 1s/step - loss: 0.1130 - auc: 0.9951 - Precision: 0.9631 - Recall: 0.9618 - categorical_accuracy: 0.9622 - val_loss: 0.9245 - val_auc: 0.8801 - val_Precision: 0.7152 - val_Recall: 0.7105 - val_categorical_accuracy: 0.7171\n",
      "Epoch 21/200\n",
      "1324/1324 [==============================] - 1884s 1s/step - loss: 0.1059 - auc: 0.9963 - Precision: 0.9624 - Recall: 0.9620 - categorical_accuracy: 0.9620 - val_loss: 0.9196 - val_auc: 0.8757 - val_Precision: 0.7039 - val_Recall: 0.7039 - val_categorical_accuracy: 0.7039\n",
      "Epoch 22/200\n",
      "1324/1324 [==============================] - 1888s 1s/step - loss: 0.1118 - auc: 0.9955 - Precision: 0.9611 - Recall: 0.9601 - categorical_accuracy: 0.9603 - val_loss: 1.1332 - val_auc: 0.8511 - val_Precision: 0.6959 - val_Recall: 0.6776 - val_categorical_accuracy: 0.6974\n",
      "Epoch 23/200\n",
      "1324/1324 [==============================] - 1877s 1s/step - loss: 0.1087 - auc: 0.9961 - Precision: 0.9612 - Recall: 0.9600 - categorical_accuracy: 0.9605 - val_loss: 0.8575 - val_auc: 0.8818 - val_Precision: 0.7171 - val_Recall: 0.7171 - val_categorical_accuracy: 0.7171\n",
      "Epoch 24/200\n",
      "1324/1324 [==============================] - 1871s 1s/step - loss: 0.1015 - auc: 0.9960 - Precision: 0.9652 - Recall: 0.9641 - categorical_accuracy: 0.9645 - val_loss: 1.0741 - val_auc: 0.8652 - val_Precision: 0.6842 - val_Recall: 0.6842 - val_categorical_accuracy: 0.6842\n",
      "Epoch 25/200\n",
      "1324/1324 [==============================] - ETA: 0s - loss: 0.1035 - auc: 0.9964 - Precision: 0.9647 - Recall: 0.9641 - categorical_accuracy: 0.9645Restoring model weights from the end of the best epoch: 5.\n",
      "1324/1324 [==============================] - 1887s 1s/step - loss: 0.1035 - auc: 0.9964 - Precision: 0.9647 - Recall: 0.9641 - categorical_accuracy: 0.9645 - val_loss: 1.0763 - val_auc: 0.8601 - val_Precision: 0.7200 - val_Recall: 0.7105 - val_categorical_accuracy: 0.7237\n",
      "Epoch 25: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 16:10:52.467798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,1,1,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-11-19 16:10:52.488724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,1,1,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-11-19 16:10:54.521056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,1,1,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-11-19 16:10:54.551445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,1,1,64]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/T1andDWIBuckImpAgain0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/T1andDWIBuckImpAgain0/assets\n"
     ]
    }
   ],
   "source": [
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',patience = 20, verbose = 1, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(\n",
    "    dg2_train,\n",
    "    validation_data = dg_val,\n",
    "    epochs = 200,\n",
    "    verbose = 1,\n",
    "    callbacks = [early]\n",
    ")\n",
    "model.save('/lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/T1andDWIBuckImpAgain0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0af2ff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/lfs1/ashaji/Imputation_Problem/ISBI/AD/final_models/T1andDWIBuckImpAgain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ddbf834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cfd70baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5022/2532890018.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.data) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 628ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 1s 635ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for img,lbl in dg_testall:\n",
    "    for i in lbl:\n",
    "        y_true.append(i)\n",
    "    x = model.predict(img)\n",
    "    for i in x:\n",
    "        y_pred.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc04d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c84bae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = np.argmax(y_true,1)\n",
    "yp = np.argmax(y_pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4dde30da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7870967741935484"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = skm.accuracy_score(yt,yp)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b19b6569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7577975998864671"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_acc = skm.balanced_accuracy_score(yt,yp)\n",
    "bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c1e2c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187513007284079"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_auc = skm.roc_auc_score(yt,y_pred,average='micro',multi_class='ovr')\n",
    "mic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "743b7435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9053097592957201"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mac_auc = skm.roc_auc_score(yt,y_pred,average='macro',multi_class='ovr')\n",
    "mac_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6098626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPUTATION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20b78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
